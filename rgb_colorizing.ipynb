{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbdf8ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 1224, 3)\n",
      "[[ 7.070493e+02  0.000000e+00  6.040814e+02  4.575831e+01]\n",
      " [ 0.000000e+00  7.070493e+02  1.805066e+02 -3.454157e-01]\n",
      " [ 0.000000e+00  0.000000e+00  1.000000e+00  4.981016e-03]]\n",
      "[[707.0493   0.     604.0814]\n",
      " [  0.     707.0493 180.5066]\n",
      " [  0.       0.       1.    ]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[-0.06035061]\n",
      " [ 0.00175693]\n",
      " [-0.00497187]\n",
      " [ 0.99816331]]\n",
      "[-0.06035061  0.00175693 -0.00497187]\n",
      "reshaped_xy_shape (20285, 2)\n",
      "(452880, 3)\n",
      "[[0.000e+00 0.000e+00 1.700e+01 2.200e+01 1.800e+01]\n",
      " [0.000e+00 1.000e+00 1.600e+01 2.400e+01 2.800e+01]\n",
      " [0.000e+00 2.000e+00 2.500e+01 2.900e+01 3.300e+01]\n",
      " ...\n",
      " [3.690e+02 1.221e+03 2.200e+01 3.000e+01 3.700e+01]\n",
      " [3.690e+02 1.222e+03 2.200e+01 2.900e+01 3.800e+01]\n",
      " [3.690e+02 1.223e+03 2.000e+01 3.000e+01 3.500e+01]]\n",
      "[[ 11.  17.  23.]\n",
      " [ 21.  24.  21.]\n",
      " [ 17.  32.  48.]\n",
      " ...\n",
      " [187. 187. 168.]\n",
      " [192. 185. 176.]\n",
      " [185. 187. 180.]]\n",
      "[[602.0853193  141.7459889 ]\n",
      " [599.8489135  141.81345282]\n",
      " [596.12144246 149.02292823]\n",
      " ...\n",
      " [614.66395264 363.63111284]\n",
      " [613.59155258 363.5825023 ]\n",
      " [611.21590868 363.66975434]]\n",
      "(20285, 2)\n",
      "[[ 5.75274920e-02 -5.65771683e-02  1.00497187e+00  1.10000000e+01\n",
      "   1.70000000e+01  2.30000000e+01]\n",
      " [ 5.43644794e-02 -5.64817522e-02  1.00497187e+00  2.10000000e+01\n",
      "   2.40000000e+01  2.10000000e+01]\n",
      " [ 4.90926108e-02 -4.62851854e-02  1.00497187e+00  1.70000000e+01\n",
      "   3.20000000e+01  4.80000000e+01]\n",
      " ...\n",
      " [ 7.53178120e-02  2.57241294e-01  1.00497187e+00  1.87000000e+02\n",
      "   1.87000000e+02  1.68000000e+02]\n",
      " [ 7.38010860e-02  2.57172542e-01  1.00497187e+00  1.92000000e+02\n",
      "   1.85000000e+02  1.76000000e+02]\n",
      " [ 7.04411451e-02  2.57295946e-01  1.00497187e+00  1.85000000e+02\n",
      "   1.87000000e+02  1.80000000e+02]]\n",
      "[[ 9.55801071e-03 -9.88065763e-01  1.79966637e+01  1.10000000e+01\n",
      "   1.70000000e+01  2.30000000e+01]\n",
      " [-4.74691381e-02 -9.87438803e-01  1.80165767e+01  2.10000000e+01\n",
      "   2.40000000e+01  2.10000000e+01]\n",
      " [-5.13352260e-01 -2.27089877e+00  5.09645665e+01  1.70000000e+01\n",
      "   3.20000000e+01  4.80000000e+01]\n",
      " ...\n",
      " [ 1.49451259e-01  1.54007464e+00  5.95803035e+00  1.87000000e+02\n",
      "   1.87000000e+02  1.68000000e+02]\n",
      " [ 1.40448821e-01  1.54017974e+00  5.96001690e+00  1.92000000e+02\n",
      "   1.85000000e+02  1.76000000e+02]\n",
      " [ 1.20460145e-01  1.54142612e+00  5.96199145e+00  1.85000000e+02\n",
      "   1.87000000e+02  1.80000000e+02]]\n",
      "90.0\n",
      "[-0.02236671 -0.05967891 -0.332549  ]\n",
      "[ 0.06035061 -0.00175693  0.00497187]\n",
      "5.5487031647274976e-05\n",
      "16.186831730352104\n",
      "1.0049718674293782\n",
      "1.0049718674293782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df14954575148dfaa0fc61cd170e237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.3333333333333333, near=0.01, position=(0.0, -10.0, -10.0), projecti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from pythreejs import *\n",
    "import cv2\n",
    "\n",
    "calibration_file_path = \"C:/Users/leeju/OneDrive/바탕 화면/kitti_object_vis-master/kitti_object_vis-master/data/object/training/calib/000000.txt\"\n",
    "image_file_path = \"C:/Users/leeju/OneDrive/바탕 화면/kitti_object_vis-master/kitti_object_vis-master/data/object/training/image_2/000000.png\"\n",
    "lidar_data_path = \"C:/Users/leeju/OneDrive/바탕 화면/kitti_object_vis-master/kitti_object_vis-master/data/object/training/velodyne/000000.bin\"\n",
    "\n",
    "stream = open(image_file_path, \"rb\")\n",
    "bytes = bytearray(stream.read())\n",
    "numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "image_color = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "image_color = image_color[:, :, (2, 1, 0)]  # BGR -> RGB\n",
    "print(image_color.shape)\n",
    "\n",
    "# Read calibration data\n",
    "with open(calibration_file_path, 'r') as fid:\n",
    "    lines = fid.readlines()\n",
    "    #앞뒤 공백을 지우고, 띄어쓰기 기준으로 라인을 나눠 배열로 저장\n",
    "    for i in range(7):\n",
    "        lines[i] = lines[i].strip().split(' ')\n",
    "        #첫 번째 P0: 이런 것들 다 지워준다\n",
    "        del lines[i][0]\n",
    "        # 각 배열의 원소들을 한 칸씩 띄워 한 문자열로 저장\n",
    "        lines[i] = ' '.join(lines[i])\n",
    "\n",
    "    # 문자열로부터 숫자 데이터를 뽑아 배열로 저장. 분류 기준은 띄어쓰기다.(문자 -> 숫자)\n",
    "    P0 = np.fromstring(lines[0], dtype=float, sep=' ')\n",
    "    P1 = np.fromstring(lines[1], dtype=float, sep=' ')\n",
    "    P2 = np.fromstring(lines[2], dtype=float, sep=' ')\n",
    "    P3 = np.fromstring(lines[3], dtype=float, sep=' ')\n",
    "    R0_rect = np.fromstring(lines[4], dtype=float, sep=' ')\n",
    "    Tr_velo_to_cam = np.fromstring(lines[5], dtype=float, sep=' ')\n",
    "    Tr_imu_to_velo = np.fromstring(lines[6], dtype=float, sep=' ')\n",
    "    Tr_cam_to_road = np.fromstring(lines[7], dtype=float, sep=' ')\n",
    "\n",
    "#Read LiDAR data\n",
    "data = np.fromfile(lidar_data_path, dtype=np.float32).reshape(-1, 4)\n",
    "# Perform LiDAR-to-Image mapping\n",
    "R0=R0_rect.reshape(3,3)\n",
    "Tr=Tr_velo_to_cam.reshape(3,4)\n",
    "p2=P2.reshape(3,4)\n",
    "XYZ=data[:,:3].T\n",
    "\n",
    "XYZ1 = np.vstack((XYZ, np.ones(data.shape[0])))\n",
    "endgame=np.dot(R0, np.dot(Tr, XYZ1))\n",
    "real_endgame=np.vstack((endgame, np.ones(endgame.T.shape[0])))\n",
    "xy1=np.dot(p2,real_endgame)\n",
    "\n",
    "p2=P2.reshape(3,4)\n",
    "print(p2)\n",
    "\n",
    "#openCV의 decomposeProjectionMatrix 함수를 통해 K,R,T를 분리해준다.\n",
    "k2,r2,t2,_,_,_,_= cv2.decomposeProjectionMatrix(p2)\n",
    "print(k2)\n",
    "print(r2)\n",
    "\n",
    "#t2의 element가 4개인 이유는, decompose를 할 때 4X4 size를 기준으로 T를 잘라냈기 때문이다. 그렇기에 마지막 0.998은 없어도 된다.\n",
    "print(t2)\n",
    "t2=t2[:3,0]\n",
    "print(t2)\n",
    "\n",
    "weight = xy1[2, :]\n",
    "x=xy1[0,:]/weight\n",
    "y=xy1[1,:]/weight\n",
    "k = np.where(weight > 0)[0]\n",
    "valid_xy1=xy1.T[k]\n",
    "\n",
    "#world coordinate system에서의 point cloud 정보들\n",
    "valid_xy1=np.dot(np.linalg.inv(k2),valid_xy1.T)\n",
    "valid_xy1=valid_xy1.T-t2\n",
    "valid_xy1=np.dot(np.linalg.inv(r2),valid_xy1.T)\n",
    "depth_camera02=valid_xy1.T\n",
    "\n",
    "'''\n",
    "x=x[k].reshape(-1,1)\n",
    "y=y[k].reshape(-1,1)\n",
    "w=weight[k].reshape(-1,1)\n",
    "xy=np.hstack((x,y))\n",
    "xy=np.hstack((xy,w))\n",
    "sorted_indices = np.argsort(xy[:, 0])[::1]\n",
    "sorted_xy = xy[sorted_indices]\n",
    "img_x_min = min(np.where(sorted_xy[:,0]>= 0)[0])\n",
    "img_x_max = max(np.where(sorted_xy[:,0]<= img.width)[0])\n",
    "sorted_xy=sorted_xy[img_x_min:img_x_max,:]\n",
    "sorted_xy = sorted_xy[:, [1, 0,2]]\n",
    "print('sorted_xy',sorted_xy)\n",
    "sorted_indices = np.argsort(sorted_xy[:, 0])[::1]\n",
    "sorted_xy = sorted_xy[sorted_indices]\n",
    "img_y_min = min(np.where(sorted_xy[:,0]>= 0)[0])\n",
    "img_y_max = max(np.where(sorted_xy[:,0]<= img.height)[0])\n",
    "sorted_xy=sorted_xy[img_y_min:img_y_max,:]\n",
    "new_xy = sorted_xy[:, [1, 0,2]]\n",
    "print(new_xy.shape)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "사진 사이즈에 맞춰서 point cloud 잘라내는 과정\n",
    "위에 주석처리 한 것처럼 형이 했던대로 올림차순으로 정렬한다음에 정리하면 index가 뒤죽박죽돼서 복잡해지는 관계로!\n",
    "이렇게 노가다식으로 잘라냄 (그래서 형이 한 방식보다 2개 더 많은 20285개...가 있음. 즉 이 방식은 조오금 부정확하긴하다는 뜻)\n",
    "'''\n",
    "x=x[k].reshape(-1,1)\n",
    "y=y[k].reshape(-1,1)\n",
    "w=weight[k].reshape(-1,1)\n",
    "xy=np.hstack((x,y))\n",
    "\n",
    "xy_index11=np.where(xy[:,0]<1224)\n",
    "xy_index12=np.where(xy[:,0]>=0)\n",
    "xy_index21=np.where(xy[:,1]<370)\n",
    "xy_index22=np.where(xy[:,1]>=0)\n",
    "xy_index1=np.intersect1d(xy_index11,xy_index12)\n",
    "xy_index2=np.intersect1d(xy_index21,xy_index22)\n",
    "\n",
    "#xy_index: 카메라가 바라보는 범위 안에 들어오는 point cloud들에 대한 index\n",
    "xy_index=np.intersect1d(xy_index1,xy_index2)\n",
    "reshaped_xy=xy[xy_index]\n",
    "print(\"reshaped_xy_shape\",reshaped_xy.shape)\n",
    "\n",
    "RGB_to_world=np.zeros((1224*370,2)).reshape(-1,2)\n",
    "\n",
    "#pixel coordinate에서 사진의 (x,y)좌표를 matrix 형태로 저장\n",
    "for i in range(370):\n",
    "    for j in range(1224):\n",
    "        RGB_to_world[i*1224+j,0]=i\n",
    "        RGB_to_world[i*1224+j,1]=j\n",
    "image_color=image_color.reshape(-1,3)\n",
    "print(image_color.shape)\n",
    "\n",
    "#픽셀의 (x,y) 좌표와 (r,g,b)정보를 hstack해준다.\n",
    "rgb=np.hstack((RGB_to_world,image_color))\n",
    "print(rgb)\n",
    "\n",
    "#픽셀의 각 좌표 정보는 전부 정수이기 때문에, 한 픽셀 내부에 속한 점들은 모두 같은 색을 띌 수 있도록 해준다.\n",
    "int_xy=reshaped_xy.astype(int)\n",
    "rgbbb=np.zeros((len(int_xy.T[0]),3))\n",
    "for i in range(len(int_xy.T[0])):\n",
    "    indexx=int_xy[i,1]*1224+int_xy[i,0]\n",
    "    rgbbb[i]=rgb[indexx,2:6]\n",
    "print(rgbbb)\n",
    "\n",
    "print(reshaped_xy)\n",
    "print(reshaped_xy.shape)\n",
    "\n",
    "image_point_tmp=np.vstack((reshaped_xy.T,np.ones(reshaped_xy.T[0].shape)))\n",
    "\n",
    "image_point_tmp=np.dot(np.linalg.inv(k2),image_point_tmp)\n",
    "image_point_tmp=image_point_tmp.T-t2\n",
    "image_point_tmp=np.dot(np.linalg.inv(r2),image_point_tmp.T)\n",
    "\n",
    "#image_point를 display하면? 사진의 상이 맻히는 거리에 사진의 형태로 point cloud가 찍힌다.\n",
    "image_point=np.hstack((image_point_tmp.T,rgbbb))\n",
    "print(image_point)\n",
    "\n",
    "#image_point2를 display하면? 우리가 원하는 형태의 point cloud를 얻을 수 있다.\n",
    "image_point2=np.hstack((depth_camera02[xy_index],rgbbb))\n",
    "print(image_point2)\n",
    "\n",
    "Fov= 2*math.atan(p2[1,1]/p2[0,0])*(180/pi)\n",
    "print(Fov)\n",
    "\n",
    "normalized_RGB_color = image_point2 / 255.0\n",
    "geometry = BufferGeometry(\n",
    "     attributes={\n",
    "        'position': BufferAttribute(image_point2[:,:3], normalized=False),\n",
    "        'color': BufferAttribute(normalized_RGB_color[:,3:6], normalized=True)\n",
    "     }\n",
    " )\n",
    "\n",
    "material = PointsMaterial(size=0.1, vertexColors='VertexColors')\n",
    "point=Points(geometry=geometry, material=material)\n",
    "\n",
    "camera = PerspectiveCamera(up=[0,0,1], position=[0,-10,-10], near=0.01, aspect=400/300)\n",
    "key_light = DirectionalLight(position=[0, 10, 10])\n",
    "ambient_light = AmbientLight()\n",
    "scene=Scene(children=[point,camera,key_light,ambient_light], background=None)\n",
    "scene.add(AxesHelper(size=3))\n",
    "\n",
    "lidar_position=np.dot(R0,np.dot(Tr,[0,0,0,1]))\n",
    "print(lidar_position)\n",
    "\n",
    "#Lidar sensor를 표현해주기 위한 PointLightHelper\n",
    "point_light = PointLight(color=\"#ffffff\", intensity=1, distance=100)\n",
    "lidar_position=(lidar_position[0],lidar_position[1],lidar_position[2])\n",
    "point_light_helper = PointLightHelper(point_light, position=lidar_position, distance=0.1, sphereSize=0.1)\n",
    "scene.add(point_light)\n",
    "scene.add(point_light_helper)\n",
    "\n",
    "cam_position=[0,0,0]\n",
    "cam_position=np.dot(np.linalg.inv(k2),cam_position)\n",
    "cam_position=cam_position-t2\n",
    "cam_position=np.dot(np.linalg.inv(r2),cam_position)\n",
    "print(cam_position)\n",
    "\n",
    "near_condition=np.where(image_point2[:,0]>=0)\n",
    "near=np.min(image_point2[near_condition,0])\n",
    "far=np.max(image_point2[:,0])\n",
    "\n",
    "#near값을 확인해보면 매우 작은 걸 알 수 있다! 이걸로는 near를 표현하기 조금...\n",
    "print(near)\n",
    "print(far)\n",
    "\n",
    "#image_point의 depth값의 의미하는 바: 카메라의 상이 맺히는 거리!(맞나?) 이 값을 near로 잡아주면 어떨까?\n",
    "#뭔가 애매하긴 하지만, near의 기준으로 잡을만한 게 지금으로썬 없는 거 같다.\n",
    "print(np.min(image_point[:,2]))\n",
    "print(np.max(image_point[:,2]))\n",
    "near=np.max(image_point[:,2])\n",
    "\n",
    "#생각해보니 pythreejs의 axihelper하고 카메라 axis가 다르니 position을 다시 고려해야할듯 \n",
    "cam=PerspectiveCamera(up=[0,0,-1], position=(cam_position[0],cam_position[1],cam_position[2]), aspect=370/1224, fov=Fov, near=near, far=far)\n",
    "camera_helper = CameraHelper(cam)\n",
    "camera_helper.rotateX(math.pi)\n",
    "camera_helper.rotateZ(math.pi/2)\n",
    "scene.add(camera_helper)\n",
    "\n",
    "controller=OrbitControls(controlling=camera)\n",
    "renderer=Renderer(camera=camera, scene=scene, controls=[controller],width=800,height=600)\n",
    "display(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa2cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
